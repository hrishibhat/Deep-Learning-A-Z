{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# setup numpy print options to see float values upto 2 decimal\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.2f}\".format(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "X = dataset.iloc[:, 3:13].values\n",
    "y = dataset.iloc[:, 13].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[619 'France' 'Female' 42 2 0.0 1 1 1 101348.88]\n",
      " [608 'Spain' 'Female' 41 1 83807.86 1 0 1 112542.58]\n",
      " [502 'France' 'Female' 42 8 159660.8 3 1 0 113931.57]\n",
      " [699 'France' 'Female' 39 1 0.0 2 0 0 93826.63]\n",
      " [850 'Spain' 'Female' 43 2 125510.82 1 1 1 79084.1]]\n",
      "[1 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print (X[0:5])\n",
    "print (y[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[619 0 0 42 2 0.0 1 1 1 101348.88]\n",
      " [608 2 0 41 1 83807.86 1 0 1 112542.58]\n",
      " [502 0 0 42 8 159660.8 3 1 0 113931.57]\n",
      " [699 0 0 39 1 0.0 2 0 0 93826.63]\n",
      " [850 2 0 43 2 125510.82 1 1 1 79084.1]]\n"
     ]
    }
   ],
   "source": [
    "print (X[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00 0.00 0.00 619.00 0.00 42.00 2.00 0.00 1.00 1.00 1.00 101348.88]\n",
      " [0.00 0.00 1.00 608.00 0.00 41.00 1.00 83807.86 1.00 0.00 1.00 112542.58]\n",
      " [1.00 0.00 0.00 502.00 0.00 42.00 8.00 159660.80 3.00 1.00 0.00 113931.57]\n",
      " [1.00 0.00 0.00 699.00 0.00 39.00 1.00 0.00 2.00 0.00 0.00 93826.63]\n",
      " [0.00 0.00 1.00 850.00 0.00 43.00 2.00 125510.82 1.00 1.00 1.00 79084.10]]\n"
     ]
    }
   ],
   "source": [
    "# one hot encoding on country (at index 1) to have dummy_france, dummy_germany, dummy_spain\n",
    "onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "print (X[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00 0.00 619.00 0.00 42.00 2.00 0.00 1.00 1.00 1.00 101348.88]\n",
      " [0.00 1.00 608.00 0.00 41.00 1.00 83807.86 1.00 0.00 1.00 112542.58]\n",
      " [0.00 0.00 502.00 0.00 42.00 8.00 159660.80 3.00 1.00 0.00 113931.57]\n",
      " [0.00 0.00 699.00 0.00 39.00 1.00 0.00 2.00 0.00 0.00 93826.63]\n",
      " [0.00 1.00 850.00 0.00 43.00 2.00 125510.82 1.00 1.00 1.00 79084.10]]\n"
     ]
    }
   ],
   "source": [
    "# drop first row dummy_france for avoiding dummy variable trap\n",
    "X = X[:, 1:]\n",
    "print (X[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00 1.00 667.00 0.00 34.00 5.00 0.00 2.00 1.00 0.00 163830.64]\n",
      " [1.00 0.00 427.00 1.00 42.00 1.00 75681.52 1.00 1.00 1.00 57098.00]\n",
      " [0.00 0.00 535.00 0.00 29.00 2.00 112367.34 1.00 1.00 0.00 185630.76]\n",
      " [0.00 1.00 654.00 1.00 40.00 5.00 105683.63 1.00 1.00 0.00 173617.09]\n",
      " [0.00 1.00 850.00 0.00 57.00 8.00 126776.30 2.00 1.00 1.00 132298.49]]\n",
      "[[1.00 0.00 597.00 0.00 35.00 8.00 131101.04 1.00 1.00 1.00 192852.67]\n",
      " [0.00 0.00 523.00 0.00 40.00 2.00 102967.41 1.00 1.00 0.00 128702.10]\n",
      " [0.00 1.00 706.00 0.00 42.00 8.00 95386.82 1.00 1.00 1.00 75732.25]\n",
      " [0.00 0.00 788.00 1.00 32.00 4.00 112079.58 1.00 0.00 0.00 89368.59]\n",
      " [1.00 0.00 706.00 1.00 38.00 5.00 163034.82 2.00 1.00 1.00 135662.17]]\n",
      "[0 0 0 0 0]\n",
      "[0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print (X_train[0:5])\n",
    "print (X_test[0:5])\n",
    "print (y_train[0:5])\n",
    "print (y_test[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.57 1.74 0.17 -1.09 -0.46 0.01 -1.22 0.81 0.64 -1.03 1.11]\n",
      " [1.75 -0.57 -2.30 0.92 0.30 -1.38 -0.01 -0.92 0.64 0.97 -0.75]\n",
      " [-0.57 -0.57 -1.19 -1.09 -0.94 -1.03 0.58 -0.92 0.64 -1.03 1.49]\n",
      " [-0.57 1.74 0.04 0.92 0.11 0.01 0.47 -0.92 0.64 -1.03 1.28]\n",
      " [-0.57 1.74 2.06 -1.09 1.74 1.04 0.81 0.81 0.64 0.97 0.56]]\n",
      "[[1.75 -0.57 -0.55 -1.09 -0.37 1.04 0.88 -0.92 0.64 0.97 1.61]\n",
      " [-0.57 -0.57 -1.31 -1.09 0.11 -1.03 0.43 -0.92 0.64 -1.03 0.50]\n",
      " [-0.57 1.74 0.57 -1.09 0.30 1.04 0.31 -0.92 0.64 0.97 -0.42]\n",
      " [-0.57 -0.57 1.42 0.92 -0.66 -0.34 0.58 -0.92 -1.56 -1.03 -0.19]\n",
      " [1.75 -0.57 0.57 0.92 -0.08 0.01 1.39 0.81 0.64 0.97 0.62]]\n",
      "[0 0 0 0 0]\n",
      "[0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "print (X_train[0:5])\n",
    "print (X_test[0:5])\n",
    "print (y_train[0:5])\n",
    "print (y_test[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Now let's make the ANN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'glorot_uniform', activation = 'relu', input_dim = 11))\n",
    "# classifier.add(Dropout(p = 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'glorot_uniform', activation = 'relu', input_dim = 6))\n",
    "# classifier.add(Dropout(p = 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'glorot_uniform', activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "8000/8000 [==============================] - 3s - loss: 0.5364 - acc: 0.7941     \n",
      "Epoch 2/30\n",
      "8000/8000 [==============================] - 2s - loss: 0.4561 - acc: 0.7960     \n",
      "Epoch 3/30\n",
      "8000/8000 [==============================] - 2s - loss: 0.4358 - acc: 0.7960     \n",
      "Epoch 4/30\n",
      "8000/8000 [==============================] - 3s - loss: 0.4321 - acc: 0.7960     \n",
      "Epoch 5/30\n",
      "8000/8000 [==============================] - 3s - loss: 0.4301 - acc: 0.7960     \n",
      "Epoch 6/30\n",
      "8000/8000 [==============================] - 2s - loss: 0.4281 - acc: 0.7960     \n",
      "Epoch 7/30\n",
      "8000/8000 [==============================] - 2s - loss: 0.4238 - acc: 0.8070     \n",
      "Epoch 8/30\n",
      "8000/8000 [==============================] - 2s - loss: 0.4194 - acc: 0.8264     \n",
      "Epoch 9/30\n",
      "8000/8000 [==============================] - 3s - loss: 0.4155 - acc: 0.8321     \n",
      "Epoch 10/30\n",
      "8000/8000 [==============================] - 3s - loss: 0.4127 - acc: 0.8319     \n",
      "Epoch 11/30\n",
      "8000/8000 [==============================] - 2s - loss: 0.4103 - acc: 0.8330     \n",
      "Epoch 12/30\n",
      "8000/8000 [==============================] - 2s - loss: 0.4078 - acc: 0.8355     \n",
      "Epoch 13/30\n",
      "8000/8000 [==============================] - 3s - loss: 0.4060 - acc: 0.8361     \n",
      "Epoch 14/30\n",
      "8000/8000 [==============================] - 2s - loss: 0.4041 - acc: 0.8362     \n",
      "Epoch 15/30\n",
      "8000/8000 [==============================] - 2s - loss: 0.4016 - acc: 0.8399     \n",
      "Epoch 16/30\n",
      "8000/8000 [==============================] - 2s - loss: 0.3983 - acc: 0.8376     \n",
      "Epoch 17/30\n",
      "8000/8000 [==============================] - 2s - loss: 0.3924 - acc: 0.8412     \n",
      "Epoch 18/30\n",
      "8000/8000 [==============================] - 3s - loss: 0.3844 - acc: 0.8446     \n",
      "Epoch 19/30\n",
      "8000/8000 [==============================] - 2s - loss: 0.3758 - acc: 0.8484     \n",
      "Epoch 20/30\n",
      "8000/8000 [==============================] - 2s - loss: 0.3687 - acc: 0.8497     \n",
      "Epoch 21/30\n",
      "8000/8000 [==============================] - 2s - loss: 0.3632 - acc: 0.8537     \n",
      "Epoch 22/30\n",
      "8000/8000 [==============================] - 2s - loss: 0.3596 - acc: 0.8571     \n",
      "Epoch 23/30\n",
      "8000/8000 [==============================] - 2s - loss: 0.3554 - acc: 0.8569     \n",
      "Epoch 24/30\n",
      "8000/8000 [==============================] - 3s - loss: 0.3543 - acc: 0.8571     \n",
      "Epoch 25/30\n",
      "8000/8000 [==============================] - 3s - loss: 0.3518 - acc: 0.8589     \n",
      "Epoch 26/30\n",
      "8000/8000 [==============================] - 3s - loss: 0.3514 - acc: 0.8599     \n",
      "Epoch 27/30\n",
      "8000/8000 [==============================] - 3s - loss: 0.3498 - acc: 0.8576     \n",
      "Epoch 28/30\n",
      "8000/8000 [==============================] - 3s - loss: 0.3490 - acc: 0.8591     \n",
      "Epoch 29/30\n",
      "8000/8000 [==============================] - 3s - loss: 0.3481 - acc: 0.8607     \n",
      "Epoch 30/30\n",
      "8000/8000 [==============================] - 3s - loss: 0.3473 - acc: 0.8596     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11c514198>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Making predictions and evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1888/2000 [===========================>..] - ETA: 0s\n",
      " Loss and Accuracy Score: [0.34020132279396059, 0.85499999999999998]\n"
     ]
    }
   ],
   "source": [
    "# Keras evaluate method\n",
    "score = classifier.evaluate(X_test, y_test)\n",
    "print (\"\\n Loss and Accuracy Score:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.13]\n",
      " [0.32]\n",
      " [0.14]\n",
      " ..., \n",
      " [0.18]\n",
      " [0.10]\n",
      " [0.13]]\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "print (y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False]\n",
      " [False]\n",
      " [False]\n",
      " ..., \n",
      " [False]\n",
      " [False]\n",
      " [False]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_bool = (y_pred > 0.5)\n",
    "print (y_pred_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1548   47]\n",
      " [ 261  144]]\n",
      "1548\n",
      "144\n"
     ]
    }
   ],
   "source": [
    "print (cm)\n",
    "# print (cm[[0][0]])\n",
    "print (cm[[0][0]][0])\n",
    "# print (cm[[1][0]])\n",
    "print (cm[[1][0]][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.846\n"
     ]
    }
   ],
   "source": [
    "print ('Accuracy:', (cm[[0][0]][0] + cm[[1][0]][1]) / len(y_pred_bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 - Evaluating, Improving and Tuning the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_classifier():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'glorot_uniform', activation = 'relu', input_dim = 11))\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'glorot_uniform', activation = 'relu', input_dim = 6))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'glorot_uniform', activation = 'sigmoid', input_dim = 6))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "Epoch 1/10\n",
      "6400/6400 [==============================] - 3s - loss: 0.5487 - acc: 0.7423     \n",
      "6400/6400 [==============================] - 3s - loss: 0.5484 - acc: 0.7411     \n",
      "Epoch 2/10\n",
      "6280/6400 [============================>.] - ETA: 0s - loss: 0.5461 - acc: 0.7427Epoch 2/10\n",
      "6400/6400 [==============================] - 3s - loss: 0.5449 - acc: 0.7428     \n",
      "Epoch 2/10\n",
      "6400/6400 [==============================] - 3s - loss: 0.5430 - acc: 0.7495     \n",
      "Epoch 2/10\n",
      "6390/6400 [============================>.] - ETA: 0s - loss: 0.4562 - acc: 0.7997\n",
      "6390/6400 [============================>.] - ETA: 0s - loss: 0.4519 - acc: 0.8011Epoch 3/10\n",
      "6400/6400 [==============================] - 2s - loss: 0.4562 - acc: 0.7997     \n",
      "5980/6400 [===========================>..] - ETA: 0s - loss: 0.4516 - acc: 0.8038Epoch 3/10\n",
      "  10/6400 [..............................] - ETA: 3s - loss: 0.5227 - acc: 0.8000\n",
      "  10/6400 [..............................] - ETA: 2s - loss: 0.4487 - acc: 0.8000Epoch 3/10\n",
      "6400/6400 [==============================] - 2s - loss: 0.4500 - acc: 0.8044     \n",
      " 360/6400 [>.............................] - ETA: 1s - loss: 0.4320 - acc: 0.7972Epoch 3/10\n",
      "6400/6400 [==============================] - 2s - loss: 0.4350 - acc: 0.8097     \n",
      "\n",
      "Epoch 4/10\n",
      "Epoch 4/10\n",
      "6400/6400 [==============================] - 2s - loss: 0.4275 - acc: 0.8152     \n",
      "Epoch 4/10\n",
      "6400/6400 [==============================] - 2s - loss: 0.4278 - acc: 0.8156     \n",
      " 470/6400 [=>............................] - ETA: 2s - loss: 0.4003 - acc: 0.8298Epoch 4/10\n",
      "6250/6400 [============================>.] - ETA: 0s - loss: 0.4258 - acc: 0.8141\n",
      "6050/6400 [===========================>..] - ETA: 0s - loss: 0.4191 - acc: 0.8167Epoch 5/10\n",
      "6400/6400 [==============================] - 2s - loss: 0.4243 - acc: 0.8150     \n",
      "Epoch 5/10\n",
      "6400/6400 [==============================] - 2s - loss: 0.4179 - acc: 0.8195     \n",
      "6400/6400 [==============================] - 2s - loss: 0.4179 - acc: 0.8173     Epoch 5/10\n",
      "\n",
      " 330/6400 [>.............................] - ETA: 1s - loss: 0.4447 - acc: 0.7970Epoch 5/10\n",
      "5960/6400 [==========================>...] - ETA: 0s - loss: 0.4121 - acc: 0.8191\n",
      "Epoch 6/10\n",
      "6400/6400 [==============================] - 2s - loss: 0.4104 - acc: 0.8228     \n",
      "Epoch 6/10\n",
      "6400/6400 [==============================] - 2s - loss: 0.4108 - acc: 0.8225     \n",
      " 370/6400 [>.............................] - ETA: 2s - loss: 0.4150 - acc: 0.8297Epoch 6/10\n",
      "6400/6400 [==============================] - 2s - loss: 0.4120 - acc: 0.8192     \n",
      "Epoch 6/10\n",
      "6400/6400 [==============================] - 2s - loss: 0.4015 - acc: 0.8250     \n",
      "Epoch 7/10\n",
      "6400/6400 [==============================] - 2s - loss: 0.4061 - acc: 0.8234     \n",
      "Epoch 7/10\n",
      " 290/6400 [>.............................] - ETA: 2s - loss: 0.3796 - acc: 0.8276\n",
      "6150/6400 [===========================>..] - ETA: 0s - loss: 0.4024 - acc: 0.8244Epoch 7/10\n",
      "6400/6400 [==============================] - 2s - loss: 0.4048 - acc: 0.8233     \n",
      "Epoch 7/10\n",
      "5860/6400 [==========================>...] - ETA: 0s - loss: 0.3811 - acc: 0.8377\n",
      "5930/6400 [==========================>...] - ETA: 0s - loss: 0.3802 - acc: 0.8381Epoch 8/10\n",
      "6400/6400 [==============================] - 2s - loss: 0.3995 - acc: 0.8230     \n",
      "Epoch 8/10\n",
      " 110/6400 [..............................] - ETA: 3s - loss: 0.4420 - acc: 0.8545\n",
      "Epoch 8/10\n",
      "6400/6400 [==============================] - 2s - loss: 0.3804 - acc: 0.8384     \n",
      "Epoch 8/10\n",
      "6400/6400 [==============================] - 2s - loss: 0.3750 - acc: 0.8452     \n",
      "6010/6400 [===========================>..] - ETA: 0s - loss: 0.3744 - acc: 0.8408Epoch 9/10\n",
      "6400/6400 [==============================] - 2s - loss: 0.3904 - acc: 0.8312     \n",
      "Epoch 9/10\n",
      "6400/6400 [==============================] - 2s - loss: 0.3710 - acc: 0.8439     \n",
      " 440/6400 [=>............................] - ETA: 2s - loss: 0.3138 - acc: 0.8773Epoch 9/10\n",
      "6400/6400 [==============================] - 2s - loss: 0.3942 - acc: 0.8269     \n",
      "Epoch 9/10\n",
      "6320/6400 [============================>.] - ETA: 0s - loss: 0.3806 - acc: 0.8380\n",
      "6290/6400 [============================>.] - ETA: 0s - loss: 0.3890 - acc: 0.8328Epoch 10/10\n",
      "6400/6400 [==============================] - 2s - loss: 0.3799 - acc: 0.8384     \n",
      "6170/6400 [===========================>..] - ETA: 0s - loss: 0.3665 - acc: 0.8452Epoch 10/10\n",
      "6400/6400 [==============================] - 2s - loss: 0.3880 - acc: 0.8333     \n",
      "Epoch 10/10\n",
      " 310/6400 [>.............................] - ETA: 2s - loss: 0.3870 - acc: 0.8290\n",
      "Epoch 10/10\n",
      "6400/6400 [==============================] - 2s - loss: 0.3718 - acc: 0.8439     \n",
      "6400/6400 [==============================] - 2s - loss: 0.3796 - acc: 0.8364     \n",
      "6280/6400 [============================>.] - ETA: 0s - loss: 0.3632 - acc: 0.8475\n",
      "6400/6400 [==============================] - 2s - loss: 0.3621 - acc: 0.8477     \n",
      "1140/1600 [====================>.........] - ETA: 0sEpoch 1/10\n",
      "6400/6400 [==============================] - 1s - loss: 0.5299 - acc: 0.7436     \n",
      "Epoch 2/10\n",
      "6400/6400 [==============================] - 1s - loss: 0.4420 - acc: 0.8008     \n",
      "Epoch 3/10\n",
      "6400/6400 [==============================] - 1s - loss: 0.4133 - acc: 0.8123     \n",
      "Epoch 4/10\n",
      "6400/6400 [==============================] - 1s - loss: 0.3848 - acc: 0.8359     \n",
      "Epoch 5/10\n",
      "6400/6400 [==============================] - 1s - loss: 0.3672 - acc: 0.8456     \n",
      "Epoch 6/10\n",
      "6400/6400 [==============================] - 1s - loss: 0.3585 - acc: 0.8464     \n",
      "Epoch 7/10\n",
      "6400/6400 [==============================] - 1s - loss: 0.3542 - acc: 0.8491     \n",
      "Epoch 8/10\n",
      "6400/6400 [==============================] - 1s - loss: 0.3504 - acc: 0.8502     \n",
      "Epoch 9/10\n",
      "6400/6400 [==============================] - 1s - loss: 0.3481 - acc: 0.8527     \n",
      "Epoch 10/10\n",
      "6400/6400 [==============================] - 1s - loss: 0.3455 - acc: 0.8537     \n",
      "1440/1600 [==========================>...] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "classifier = KerasClassifier(build_fn = build_classifier, batch_size = 10, epochs = 20)\n",
    "\n",
    "# K Fold Cross Validation method from sklearn.model_selection\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 0.846374994442\n",
      "variance 0.00708651843628\n"
     ]
    }
   ],
   "source": [
    "#  now to see bias-variance tradeoff\n",
    "# bias\n",
    "mean = accuracies.mean()\n",
    "\n",
    "# variance\n",
    "variance = accuracies.std()\n",
    "\n",
    "print ('mean', mean)\n",
    "print ('variance',variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tuning the ANN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "def build_classifier(optimizer):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n",
    "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier\n",
    "classifier = KerasClassifier(build_fn = build_classifier)\n",
    "parameters = {'batch_size': [25, 32],\n",
    "              'epochs': [100, 500],\n",
    "              'optimizer': ['adam', 'rmsprop']}\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 10)\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
