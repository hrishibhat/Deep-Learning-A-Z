{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import usual suspects\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "      <td>35</td>\n",
       "      <td>45</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>31</td>\n",
       "      <td>34</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>39</td>\n",
       "      <td>50</td>\n",
       "      <td>54</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>32</td>\n",
       "      <td>38</td>\n",
       "      <td>47</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3   4   5\n",
       "0   8  13  26  35  45  51\n",
       "1   1  15  24  31  34  44\n",
       "2   3   8  29  30  31  49\n",
       "3  21  25  39  50  54  59\n",
       "4  15  19  32  38  47  50"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing  the training set\n",
    "pd_training_set = pd.read_csv('Lottery_NY_Lotto_Winning_Numbers__Beginning_2001_without_bonus.csv', header=None)\n",
    "pd_training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Set\n",
    "# now add each column of six rows into next 6 rows of first column\n",
    "two_dim_lotto_array_train = []\n",
    "# take 300 rows less from total for testing and rest use for training\n",
    "# for col in pd_training_set.iloc[:-300,:].values:\n",
    "for col in pd_training_set.iloc[:,:].values:\n",
    "#     print (col)\n",
    "    for row in col:\n",
    "        two_dim_lotto_array_train.append([row])\n",
    "#         print (row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "2\n",
      "(9768, 1)\n",
      "[[ 8]\n",
      " [13]\n",
      " [26]\n",
      " ..., \n",
      " [17]\n",
      " [26]\n",
      " [55]]\n"
     ]
    }
   ],
   "source": [
    "# convert python list into numpy array\n",
    "training_set_val = np.array(two_dim_lotto_array_train, ndmin=2)\n",
    "\n",
    "print (type(training_set_val))\n",
    "print (training_set_val.ndim)\n",
    "print (training_set_val.shape)\n",
    "print (training_set_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.73333333]\n",
      " [-0.56666667]\n",
      " [-0.13333333]\n",
      " ..., \n",
      " [-0.43333333]\n",
      " [-0.13333333]\n",
      " [ 0.83333333]]\n",
      "<class 'numpy.ndarray'>\n",
      "2\n",
      "(9768, 1)\n"
     ]
    }
   ],
   "source": [
    "# # Now, let's do normalization\n",
    "\n",
    "# # from sklearn.preprocessing import MinMaxScaler\n",
    "# # sc = MinMaxScaler()\n",
    "# # # Accuracy: 0.0317802805365\n",
    "\n",
    "# from sklearn.preprocessing import MaxAbsScaler\n",
    "# sc = MaxAbsScaler()\n",
    "# #  Accuracy: 0.0293846626395\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "sc = RobustScaler()\n",
    "# Accuracy: 0.0377802805365\n",
    "\n",
    "\n",
    "training_set = sc.fit_transform(training_set_val)\n",
    "print (training_set)\n",
    "print (type(training_set))\n",
    "print (training_set.ndim)\n",
    "print (training_set.shape)\n",
    "\n",
    "# # ALSO TRY STANDARDIZATION INSTEAD OF NORMALIZATION\n",
    "\n",
    "# # from sklearn.preprocessing import StandardScaler\n",
    "# # sc = StandardScaler()\n",
    "\n",
    "# # training_set = sc.fit_transform(training_set_val)\n",
    "# # print (training_set)\n",
    "# # print (type(training_set))\n",
    "# # print (training_set.ndim)\n",
    "# # print (training_set.shape)\n",
    "\n",
    "# # NO NORMALIZATION\n",
    "# training_set = training_set_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a data structure with 60 timesteps and t+1 output\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(600, 9768):\n",
    "    X_train.append(training_set[i-600:i, 0])\n",
    "    y_train.append(training_set[i, 0])\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9168, 600, 1)\n",
      "[[[-0.73333333]\n",
      "  [-0.56666667]\n",
      "  [-0.13333333]\n",
      "  ..., \n",
      "  [ 0.06666667]\n",
      "  [ 0.13333333]\n",
      "  [ 0.6       ]]\n",
      "\n",
      " [[-0.56666667]\n",
      "  [-0.13333333]\n",
      "  [ 0.16666667]\n",
      "  ..., \n",
      "  [ 0.13333333]\n",
      "  [ 0.6       ]\n",
      "  [-0.7       ]]\n",
      "\n",
      " [[-0.13333333]\n",
      "  [ 0.16666667]\n",
      "  [ 0.5       ]\n",
      "  ..., \n",
      "  [ 0.6       ]\n",
      "  [-0.7       ]\n",
      "  [ 0.16666667]]\n",
      "\n",
      " ..., \n",
      " [[ 0.        ]\n",
      "  [ 0.03333333]\n",
      "  [ 0.9       ]\n",
      "  ..., \n",
      "  [-0.86666667]\n",
      "  [-0.76666667]\n",
      "  [-0.6       ]]\n",
      "\n",
      " [[ 0.03333333]\n",
      "  [ 0.9       ]\n",
      "  [-0.46666667]\n",
      "  ..., \n",
      "  [-0.76666667]\n",
      "  [-0.6       ]\n",
      "  [-0.43333333]]\n",
      "\n",
      " [[ 0.9       ]\n",
      "  [-0.46666667]\n",
      "  [-0.4       ]\n",
      "  ..., \n",
      "  [-0.6       ]\n",
      "  [-0.43333333]\n",
      "  [-0.13333333]]]\n"
     ]
    }
   ],
   "source": [
    "# Now, Reshaping for keras before training, as it requires 3 dimenions\n",
    "\n",
    "# changing from 2 to 3 dimension array, by addding time step as 3rd dimension\n",
    "# corresponds to (batch_size, timesteps, input_dim)\n",
    "# X_train = np.reshape(X_train,(7967,1,1))\n",
    "\n",
    "# Reshaping\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "\n",
    "print (X_train.shape)\n",
    "print (X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Initializing the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing the Keras liabraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a regressor bassed upon sequential RNN\n",
    "# classifier = Sequential()\n",
    "# classifier.add(LSTM(units=10, activation='sigmoid', input_shape=(None, 1)))\n",
    "# classifier.add(Dense(units=1))\n",
    "regressor = Sequential()\n",
    "regressor.add(LSTM(units=3, activation='sigmoid', input_shape=(None, 1), return_sequences = True))\n",
    "regressor.add(LSTM(units=3, activation='sigmoid', return_sequences = True))\n",
    "regressor.add(LSTM(units=3, activation='sigmoid', return_sequences = True))\n",
    "regressor.add(LSTM(units=3, activation='sigmoid'))\n",
    "regressor.add(Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now, let' compile our RNN regressor\n",
    "# classifier.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "regressor.compile(optimizer='rmsprop', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "9168/9168 [==============================] - 162s - loss: 0.3543   \n",
      "Epoch 2/5\n",
      "9168/9168 [==============================] - 145s - loss: 0.3239   \n",
      "Epoch 3/5\n",
      "9168/9168 [==============================] - 145s - loss: 0.3216   \n",
      "Epoch 4/5\n",
      "2816/9168 [========>.....................] - ETA: 100s - loss: 0.3127"
     ]
    }
   ],
   "source": [
    "# regressor.fit(X_train ,y_train, batch_size=32, epochs=50) with 4 LSTM and time 60 i achieved 0.0219 loss\n",
    "\n",
    "regressor.fit(X_train ,y_train, batch_size=256, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "regressor.save('lotto_regressor__1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Making Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "model = load_model('lotto_regressor__1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing Set\n",
    "# now add each column of six rows into next 6 rows of first column\n",
    "two_dim_lotto_array_test = []\n",
    "# take all rows less from total for testing and rest use for training\n",
    "for col in pd_training_set.iloc[:,:].values:\n",
    "#     print (col)\n",
    "    for row in col:\n",
    "        two_dim_lotto_array_test.append([row])\n",
    "#         print (row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert python list into numpy array\n",
    "testing_set_val = np.array(two_dim_lotto_array_test, ndmin=2)\n",
    "\n",
    "print (type(testing_set_val))\n",
    "print (testing_set_val.ndim)\n",
    "print (testing_set_val.shape)\n",
    "print (testing_set_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOw let's concatenate training_set with testing_set_val\n",
    "real_lotto_numbers = testing_set_val\n",
    "# real_lotto_numbers = np.concatenate((training_set[0:7968], testing_set_val), axis = 0)\n",
    "print (type(real_lotto_numbers))\n",
    "print (real_lotto_numbers.ndim)\n",
    "print (real_lotto_numbers.shape)\n",
    "# print (real_lotto_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_test = real_lotto_numbers[0:7967]\n",
    "# X_test = sc.fit_transform(X_test)\n",
    "# print (type(X_test))\n",
    "# print (X_test.ndim)\n",
    "# print (X_test.shape)\n",
    "# print (X_test)\n",
    "# # in the end inverse fit transform to get normal stock open price back\n",
    "# # X_test = real_lotto_numbers\n",
    "\n",
    "scaled_real_lotto_number = sc.fit_transform(real_lotto_numbers)\n",
    "inputs = []\n",
    "for i in range(60, 9768):\n",
    "    inputs.append(scaled_real_lotto_number[i-60:i, 0])\n",
    "\n",
    "inputs = np.array(inputs)\n",
    "\n",
    "print (inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = np.reshape(inputs, (inputs.shape[0], inputs.shape[1],1))\n",
    "print (inputs.shape)\n",
    "predicted_lotto_numbers = model.predict(inputs)\n",
    "predicted_lotto_numbers = sc.inverse_transform(predicted_lotto_numbers)\n",
    "\n",
    "print (type(predicted_lotto_numbers))\n",
    "print (predicted_lotto_numbers.ndim)\n",
    "print (predicted_lotto_numbers.shape)\n",
    "print (predicted_lotto_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# same for X_test\n",
    "y_predicted = np.around(predicted_lotto_numbers)\n",
    "print (type(y_predicted))\n",
    "print (y_predicted.ndim)\n",
    "print (y_predicted.shape)\n",
    "print (y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_predictions = np.equal(y_predicted, real_lotto_numbers[60:])\n",
    "print (true_predictions)\n",
    "print (\"Accuracy:\", np.sum(true_predictions)/np.size(true_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Part 4: Let's Visualize the results\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(real_lotto_numbers, color='red', label = 'Real Lotto Numbers')\n",
    "plt.plot(predicted_lotto_numbers, color='blue', label = 'Predicted Lotto Numbers')\n",
    "plt.title('Lotto Numbers Prediction')\n",
    "plt.xlabel('Lotto Results')\n",
    "plt.ylabel('Lotto Numbers')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_sample = testing_set_val\n",
    "# X_sample = sc.fit_transform(X_sample)\n",
    "# print (type(X_sample))\n",
    "# print (X_sample.ndim)\n",
    "# print (X_sample.shape)\n",
    "# print (X_sample)\n",
    "# # in the end inverse fit transform to get normal stock open price back\n",
    "# # X_test = real_lotto_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # inverse scaled values to get real stock price\n",
    "# sample_lotto_numbers = np.around(sc.inverse_transform(y_sample))\n",
    "# print (type(sample_lotto_numbers))\n",
    "# print (sample_lotto_numbers.ndim)\n",
    "# print (sample_lotto_numbers.shape)\n",
    "# print (sample_lotto_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# new_shape = real_lotto_numbers.reshape((11396))\n",
    "# print (type(new_shape))\n",
    "# print (new_shape.ndim)\n",
    "# print (new_shape.shape)\n",
    "# print (new_shape)\n",
    "                           \n",
    "real_lotto_numbers_df = pd.Series(real_lotto_numbers.reshape((9768)), name='real_lotto_numbers')\n",
    "sample_lotto_numbers_df = pd.Series(sample_lotto_numbers.reshape((9768)), name='sample_lotto_numbers')\n",
    "comparison_df = pd.concat([real_lotto_numbers_df, sample_lotto_numbers_df], axis=1)\n",
    "comparison_df.tail(600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
