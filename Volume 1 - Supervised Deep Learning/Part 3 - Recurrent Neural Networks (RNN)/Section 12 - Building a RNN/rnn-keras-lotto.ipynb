{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import usual suspects\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "      <td>35</td>\n",
       "      <td>45</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>31</td>\n",
       "      <td>34</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "      <td>39</td>\n",
       "      <td>50</td>\n",
       "      <td>54</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>32</td>\n",
       "      <td>38</td>\n",
       "      <td>47</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1   2   3   4   5\n",
       "0   8  13  26  35  45  51\n",
       "1   1  15  24  31  34  44\n",
       "2   3   8  29  30  31  49\n",
       "3  21  25  39  50  54  59\n",
       "4  15  19  32  38  47  50"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing  the training set\n",
    "pd_training_set = pd.read_csv('Lottery_NY_Lotto_Winning_Numbers__Beginning_2001_without_bonus.csv', header=None)\n",
    "pd_training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Set\n",
    "# now add each column of six rows into next 6 rows of first column\n",
    "two_dim_lotto_array_train = []\n",
    "# take 300 rows less from total for testing and rest use for training\n",
    "for col in pd_training_set.iloc[:-300,:].values:\n",
    "#     print (col)\n",
    "    for row in col:\n",
    "        two_dim_lotto_array_train.append([row])\n",
    "#         print (row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "2\n",
      "(7968, 1)\n",
      "[[ 8]\n",
      " [13]\n",
      " [26]\n",
      " ..., \n",
      " [29]\n",
      " [46]\n",
      " [50]]\n"
     ]
    }
   ],
   "source": [
    "# convert python list into numpy array\n",
    "training_set_val = np.array(two_dim_lotto_array_train, ndmin=2)\n",
    "\n",
    "print (type(training_set_val))\n",
    "print (training_set_val.ndim)\n",
    "print (training_set_val.shape)\n",
    "print (training_set_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Set\n",
    "# now add each column of six rows into next 6 rows of first column\n",
    "two_dim_lotto_array_test = []\n",
    "# take 300 rows less from total for testing and rest use for training\n",
    "for col in pd_training_set.iloc[-300:,:].values:\n",
    "#     print (col)\n",
    "    for row in col:\n",
    "        two_dim_lotto_array_test.append([row])\n",
    "#         print (row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "2\n",
      "(1800, 1)\n",
      "[[ 1]\n",
      " [28]\n",
      " [38]\n",
      " ..., \n",
      " [17]\n",
      " [26]\n",
      " [55]]\n"
     ]
    }
   ],
   "source": [
    "# convert python list into numpy array\n",
    "testing_set_val = np.array(two_dim_lotto_array_test, ndmin=2)\n",
    "\n",
    "print (type(testing_set_val))\n",
    "print (testing_set_val.ndim)\n",
    "print (testing_set_val.shape)\n",
    "print (testing_set_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOw let's take only open price of stock\n",
    "# # if we choose pd_training_set.iloc[:,1].values It will be only 1 dim numpy array\n",
    "# # however, we need 2 dimension numpy array\n",
    "# training_set_val = pd_training_set.iloc[:,1:2].values\n",
    "# print (type(training_set_val))\n",
    "# print (training_set_val.ndim)\n",
    "# print (training_set_val.shape)\n",
    "# print (training_set_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now, let's do normalization\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# sc = MinMaxScaler()\n",
    "\n",
    "# training_set = sc.fit_transform(training_set_val)\n",
    "# print (training_set)\n",
    "# print (type(training_set))\n",
    "# print (training_set.ndim)\n",
    "# print (training_set.shape)\n",
    "\n",
    "# # ALSO TRY STANDARDIZATION INSTEAD OF NORMALIZATION\n",
    "\n",
    "training_set = training_set_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8]\n",
      " [13]\n",
      " [26]\n",
      " ..., \n",
      " [19]\n",
      " [29]\n",
      " [46]]\n"
     ]
    }
   ],
   "source": [
    "# Now we are setting X_train and y_train\n",
    "# X_train is time at 0 value and y_train is time at +1 value\n",
    "X_train = training_set[0:7967]\n",
    "print (X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13]\n",
      " [26]\n",
      " [35]\n",
      " ..., \n",
      " [29]\n",
      " [46]\n",
      " [50]]\n"
     ]
    }
   ],
   "source": [
    "# y_train is time+1 value\n",
    "y_train = training_set[1:7968]\n",
    "print (y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 8]]\n",
      "\n",
      " [[13]]\n",
      "\n",
      " [[26]]\n",
      "\n",
      " ..., \n",
      " [[19]]\n",
      "\n",
      " [[29]]\n",
      "\n",
      " [[46]]]\n"
     ]
    }
   ],
   "source": [
    "# Now, Reshaping for keras before training, as it requires 3 dimenions\n",
    "\n",
    "# changing from 2 to 3 dimension array, by addding time step as 3rd dimension\n",
    "# corresponds to (batch_size, timesteps, input_dim)\n",
    "X_train = np.reshape(X_train,(7967,1,1))\n",
    "print (X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Initializing the RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the Keras liabraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a regressor bassed upon sequential RNN\n",
    "# classifier = Sequential()\n",
    "# classifier.add(LSTM(units=10, activation='sigmoid', input_shape=(None, 1)))\n",
    "# classifier.add(Dense(units=1))\n",
    "regressor = Sequential()\n",
    "regressor.add(LSTM(units=10, activation='sigmoid', input_shape=(None, 1)))\n",
    "regressor.add(Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now, let' compile our RNN regressor\n",
    "# classifier.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "regressor.compile(optimizer='rmsprop', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "7967/7967 [==============================] - 1s - loss: 1129.5908     \n",
      "Epoch 2/200\n",
      "7967/7967 [==============================] - 1s - loss: 1031.2356     \n",
      "Epoch 3/200\n",
      "7967/7967 [==============================] - 1s - loss: 966.1112     \n",
      "Epoch 4/200\n",
      "7967/7967 [==============================] - 1s - loss: 906.0925     \n",
      "Epoch 5/200\n",
      "7967/7967 [==============================] - 1s - loss: 843.4392     \n",
      "Epoch 6/200\n",
      "7967/7967 [==============================] - 1s - loss: 759.0859     \n",
      "Epoch 7/200\n",
      "7967/7967 [==============================] - 1s - loss: 677.8462     \n",
      "Epoch 8/200\n",
      "7967/7967 [==============================] - 1s - loss: 609.0655     \n",
      "Epoch 9/200\n",
      "7967/7967 [==============================] - 1s - loss: 551.4665     \n",
      "Epoch 10/200\n",
      "7967/7967 [==============================] - 1s - loss: 499.8991     \n",
      "Epoch 11/200\n",
      "7967/7967 [==============================] - 1s - loss: 453.5067     \n",
      "Epoch 12/200\n",
      "7967/7967 [==============================] - 1s - loss: 412.6569     \n",
      "Epoch 13/200\n",
      "7967/7967 [==============================] - 1s - loss: 376.6594     \n",
      "Epoch 14/200\n",
      "7967/7967 [==============================] - 1s - loss: 345.3217     \n",
      "Epoch 15/200\n",
      "7967/7967 [==============================] - 1s - loss: 318.0371     \n",
      "Epoch 16/200\n",
      "7967/7967 [==============================] - 1s - loss: 294.9347     \n",
      "Epoch 17/200\n",
      "7967/7967 [==============================] - 1s - loss: 276.1457     \n",
      "Epoch 18/200\n",
      "7967/7967 [==============================] - 1s - loss: 261.4571     \n",
      "Epoch 19/200\n",
      "7967/7967 [==============================] - 1s - loss: 249.7580     \n",
      "Epoch 20/200\n",
      "7967/7967 [==============================] - 1s - loss: 241.4999     \n",
      "Epoch 21/200\n",
      "7967/7967 [==============================] - 1s - loss: 236.0957     \n",
      "Epoch 22/200\n",
      "7967/7967 [==============================] - 1s - loss: 232.9380     \n",
      "Epoch 23/200\n",
      "7967/7967 [==============================] - 1s - loss: 231.0023     \n",
      "Epoch 24/200\n",
      "7967/7967 [==============================] - 1s - loss: 229.9282     \n",
      "Epoch 25/200\n",
      "7967/7967 [==============================] - 1s - loss: 229.3195     \n",
      "Epoch 26/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.9383     \n",
      "Epoch 27/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.7820     \n",
      "Epoch 28/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.6480     \n",
      "Epoch 29/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.5722     \n",
      "Epoch 30/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.5115     \n",
      "Epoch 31/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.4614     \n",
      "Epoch 32/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3813     \n",
      "Epoch 33/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.4500     \n",
      "Epoch 34/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.4153     \n",
      "Epoch 35/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.4177     \n",
      "Epoch 36/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3989     \n",
      "Epoch 37/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3666     \n",
      "Epoch 38/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3827     \n",
      "Epoch 39/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.4141     \n",
      "Epoch 40/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3818     \n",
      "Epoch 41/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3985     \n",
      "Epoch 42/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3982     \n",
      "Epoch 43/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3708     \n",
      "Epoch 44/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3663     \n",
      "Epoch 45/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3725     \n",
      "Epoch 46/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3865     \n",
      "Epoch 47/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3950     \n",
      "Epoch 48/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3634     \n",
      "Epoch 49/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3875     \n",
      "Epoch 50/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3544     \n",
      "Epoch 51/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3671     \n",
      "Epoch 52/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3768     \n",
      "Epoch 53/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3537     \n",
      "Epoch 54/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3892     \n",
      "Epoch 55/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3814     \n",
      "Epoch 56/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3889     \n",
      "Epoch 57/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3459     \n",
      "Epoch 58/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3645     \n",
      "Epoch 59/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3671     \n",
      "Epoch 60/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3687     \n",
      "Epoch 61/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3506     \n",
      "Epoch 62/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3409     \n",
      "Epoch 63/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.4022     \n",
      "Epoch 64/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3407     \n",
      "Epoch 65/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3801     \n",
      "Epoch 66/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3529     \n",
      "Epoch 67/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3720     \n",
      "Epoch 68/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3909     \n",
      "Epoch 69/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3733     \n",
      "Epoch 70/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3725     \n",
      "Epoch 71/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3758     \n",
      "Epoch 72/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3945     \n",
      "Epoch 73/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3851     \n",
      "Epoch 74/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.4048     \n",
      "Epoch 75/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3811     \n",
      "Epoch 76/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3443     \n",
      "Epoch 77/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3823     \n",
      "Epoch 78/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3870     \n",
      "Epoch 79/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3559     \n",
      "Epoch 80/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3438     \n",
      "Epoch 81/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3744     \n",
      "Epoch 82/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3853     \n",
      "Epoch 83/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3132     \n",
      "Epoch 84/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3768     \n",
      "Epoch 85/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3694     \n",
      "Epoch 86/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3842     \n",
      "Epoch 87/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3602     \n",
      "Epoch 88/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3742     \n",
      "Epoch 89/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3752     \n",
      "Epoch 90/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3731     \n",
      "Epoch 91/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3712     \n",
      "Epoch 92/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3230     \n",
      "Epoch 93/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3732     \n",
      "Epoch 94/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3240     \n",
      "Epoch 95/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3734     \n",
      "Epoch 96/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3744     \n",
      "Epoch 97/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3506     \n",
      "Epoch 98/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3265     \n",
      "Epoch 99/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7967/7967 [==============================] - 1s - loss: 228.3767     \n",
      "Epoch 100/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3571     \n",
      "Epoch 101/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3532     \n",
      "Epoch 102/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3959     \n",
      "Epoch 103/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3563     \n",
      "Epoch 104/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3820     \n",
      "Epoch 105/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3606     \n",
      "Epoch 106/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3648     \n",
      "Epoch 107/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3786     \n",
      "Epoch 108/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3701     \n",
      "Epoch 109/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3616     \n",
      "Epoch 110/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3734     \n",
      "Epoch 111/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3491     \n",
      "Epoch 112/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3934     \n",
      "Epoch 113/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3586     \n",
      "Epoch 114/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3823     \n",
      "Epoch 115/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3632     \n",
      "Epoch 116/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3841     \n",
      "Epoch 117/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3614     \n",
      "Epoch 118/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3656     \n",
      "Epoch 119/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3257     \n",
      "Epoch 120/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3837     \n",
      "Epoch 121/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3664     \n",
      "Epoch 122/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3609     \n",
      "Epoch 123/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3523     \n",
      "Epoch 124/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3512     \n",
      "Epoch 125/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3703     \n",
      "Epoch 126/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3483     \n",
      "Epoch 127/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3576     \n",
      "Epoch 128/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3619     \n",
      "Epoch 129/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3624     \n",
      "Epoch 130/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3795     \n",
      "Epoch 131/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3480     \n",
      "Epoch 132/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3716     \n",
      "Epoch 133/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3763     \n",
      "Epoch 134/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3510     \n",
      "Epoch 135/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3776     \n",
      "Epoch 136/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3646     \n",
      "Epoch 137/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3445     \n",
      "Epoch 138/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3490     \n",
      "Epoch 139/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3842     \n",
      "Epoch 140/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3243     \n",
      "Epoch 141/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3728     \n",
      "Epoch 142/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3631     \n",
      "Epoch 143/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3645     \n",
      "Epoch 144/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3727     \n",
      "Epoch 145/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3614     \n",
      "Epoch 146/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3141     \n",
      "Epoch 147/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3751     \n",
      "Epoch 148/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3557     \n",
      "Epoch 149/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3682     \n",
      "Epoch 150/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3708     \n",
      "Epoch 151/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3686     \n",
      "Epoch 152/200\n",
      "7967/7967 [==============================] - 1s - loss: 228.3632     \n",
      "Epoch 153/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3735     \n",
      "Epoch 154/200\n",
      "7967/7967 [==============================] - 3s - loss: 228.3677     \n",
      "Epoch 155/200\n",
      "7967/7967 [==============================] - 3s - loss: 228.3620     \n",
      "Epoch 156/200\n",
      "7967/7967 [==============================] - 3s - loss: 228.3723     \n",
      "Epoch 157/200\n",
      "7967/7967 [==============================] - 3s - loss: 228.3621     \n",
      "Epoch 158/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3423     \n",
      "Epoch 159/200\n",
      "7967/7967 [==============================] - 3s - loss: 228.3771     \n",
      "Epoch 160/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3465     \n",
      "Epoch 161/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3341     \n",
      "Epoch 162/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3532     \n",
      "Epoch 163/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3628     \n",
      "Epoch 164/200\n",
      "7967/7967 [==============================] - 3s - loss: 228.2900     \n",
      "Epoch 165/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3650     \n",
      "Epoch 166/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3724     \n",
      "Epoch 167/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3585     \n",
      "Epoch 168/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3499     \n",
      "Epoch 169/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3762     \n",
      "Epoch 170/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3730     \n",
      "Epoch 171/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3643     \n",
      "Epoch 172/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3568     \n",
      "Epoch 173/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3805     \n",
      "Epoch 174/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3875     \n",
      "Epoch 175/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3495     \n",
      "Epoch 176/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3511     \n",
      "Epoch 177/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3835     \n",
      "Epoch 178/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3730     \n",
      "Epoch 179/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3655     \n",
      "Epoch 180/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3731     \n",
      "Epoch 181/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3486     \n",
      "Epoch 182/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3399     \n",
      "Epoch 183/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3939     \n",
      "Epoch 184/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3724     \n",
      "Epoch 185/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3621     \n",
      "Epoch 186/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3471     \n",
      "Epoch 187/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3689     \n",
      "Epoch 188/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3652     \n",
      "Epoch 189/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3681     \n",
      "Epoch 190/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3665     \n",
      "Epoch 191/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3554     \n",
      "Epoch 192/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3665     \n",
      "Epoch 193/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3589     \n",
      "Epoch 194/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3604     \n",
      "Epoch 195/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3572     \n",
      "Epoch 196/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7967/7967 [==============================] - 2s - loss: 228.3733     \n",
      "Epoch 197/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3417     \n",
      "Epoch 198/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3294     \n",
      "Epoch 199/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3646     \n",
      "Epoch 200/200\n",
      "7967/7967 [==============================] - 2s - loss: 228.3312     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1293685c0>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train ,y_train, batch_size=32, epochs=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Making Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Preprocessing for Test_set\n",
    "# # Importing the test set\n",
    "# pd_testing_set = pd.read_csv('Google_Stock_Price_Test.csv')\n",
    "# pd_testing_set.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "2\n",
      "(1800, 1)\n",
      "[[ 1]\n",
      " [28]\n",
      " [38]\n",
      " ..., \n",
      " [17]\n",
      " [26]\n",
      " [55]]\n"
     ]
    }
   ],
   "source": [
    "# NOw let's take only open price of stock\n",
    "# if we choose pd_training_set.iloc[:,1] It will be only 1 dim pandas series\n",
    "# however, we need 2 dimension, so\n",
    "real_lotto_numbers = testing_set_val\n",
    "print (type(real_lotto_numbers))\n",
    "print (real_lotto_numbers.ndim)\n",
    "print (real_lotto_numbers.shape)\n",
    "print (real_lotto_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = sc.fit_transform(real_lotto_numbers)\n",
    "# print (type(X_test))\n",
    "# print (X_test.ndim)\n",
    "# print (X_test.shape)\n",
    "# print (X_test)\n",
    "# # in the end inverse fit transform to get normal stock open price back\n",
    "X_test = real_lotto_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # same for X_test\n",
    "# X_test = testing_set[0:20]\n",
    "# print (X_test)\n",
    "# print (type(X_test))\n",
    "# print (X_test.ndim)\n",
    "# print (X_test.shape)\n",
    "# print (X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "3\n",
      "(1800, 1, 1)\n",
      "[[[ 1]]\n",
      "\n",
      " [[28]]\n",
      "\n",
      " [[38]]\n",
      "\n",
      " ..., \n",
      " [[17]]\n",
      "\n",
      " [[26]]\n",
      "\n",
      " [[55]]]\n"
     ]
    }
   ],
   "source": [
    "# Reshaping\n",
    "\n",
    "# chaging from 2 to 3 dimension array, by addding time step as 3rd dimension\n",
    "# corresponds to (batch_size, timesteps, input_dim)\n",
    "test_inputs = np.reshape(X_test,(1800,1,1))\n",
    "print (type(test_inputs))\n",
    "print (test_inputs.ndim)\n",
    "print (test_inputs.shape)\n",
    "print (test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's predict\n",
    "y_test = regressor.predict(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 10.74979305]\n",
      " [ 35.32204437]\n",
      " [ 35.32256699]\n",
      " ..., \n",
      " [ 26.67741966]\n",
      " [ 35.32151031]\n",
      " [ 35.32258606]]\n",
      "[[ 11.]\n",
      " [ 35.]\n",
      " [ 35.]\n",
      " ..., \n",
      " [ 27.]\n",
      " [ 35.]\n",
      " [ 35.]]\n",
      "[[ 1]\n",
      " [28]\n",
      " [38]\n",
      " ..., \n",
      " [17]\n",
      " [26]\n",
      " [55]]\n",
      "31\n",
      "0.0172222222222\n"
     ]
    }
   ],
   "source": [
    "# inverse scaled values to get real stock price\n",
    "# predicted_lotto_numbers = np.around(sc.inverse_transform(y_test))\n",
    "print (y_test)\n",
    "predicted_lotto_numbers = np.round(y_test,0)\n",
    "print (predicted_lotto_numbers)\n",
    "print (real_lotto_numbers)\n",
    "\n",
    "true_predictions = predicted_lotto_numbers == real_lotto_numbers\n",
    "print (np.sum(true_predictions))\n",
    "print (np.sum(true_predictions)/np.size(true_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Part 4: Let's Visualize the results\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nP1ClNZRQPQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x129517358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(real_lotto_numbers, color='red', label = 'Real Lotto Numbers')\n",
    "plt.plot(predicted_lotto_numbers, color='blue', label = 'Predicted Lotto Numbers')\n",
    "plt.title('Lotto Numbers Prediction')\n",
    "plt.xlabel('Lotto Results')\n",
    "plt.ylabel('Lotto Numbers')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>778.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>788.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>786.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>795.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>806.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Open\n",
       "0  778.81\n",
       "1  788.36\n",
       "2  786.08\n",
       "3  795.26\n",
       "4  806.40"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_stock_price_df = pd.DataFrame(real_stock_price)\n",
    "print (type(real_stock_price_df))\n",
    "real_stock_price_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted_Open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>779.161133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>788.316895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>786.100220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>795.131042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>806.383484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predicted_Open\n",
       "0      779.161133\n",
       "1      788.316895\n",
       "2      786.100220\n",
       "3      795.131042\n",
       "4      806.383484"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_stock_df = pd.DataFrame(predicted_stock_price, columns=['Predicted_Open'])\n",
    "print (type(predicted_stock_df))\n",
    "predicted_stock_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     778.81\n",
      "1     788.36\n",
      "2     786.08\n",
      "3     795.26\n",
      "4     806.40\n",
      "5     807.86\n",
      "6     805.00\n",
      "7     807.14\n",
      "8     807.48\n",
      "9     807.08\n",
      "10    805.81\n",
      "11    805.12\n",
      "12    806.91\n",
      "13    807.25\n",
      "14    822.30\n",
      "15    829.62\n",
      "16    837.81\n",
      "17    834.71\n",
      "18    814.66\n",
      "19    796.86\n",
      "20    799.68\n",
      "Name: Open, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print (pd_testing_set.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "2 columns passed, passed data had 21 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-e610601dd265>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcomparsion_sheet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpd_testing_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredicted_stock_price\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Real_Open_Price'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Predicted_Open_Price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcomparsion_sheet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pankajmathur/anaconda/envs/keras-playground/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    303\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mis_named_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m                     \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m                     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pankajmathur/anaconda/envs/keras-playground/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_to_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m   5539\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5540\u001b[0m         return _list_to_arrays(data, columns, coerce_float=coerce_float,\n\u001b[0;32m-> 5541\u001b[0;31m                                dtype=dtype)\n\u001b[0m\u001b[1;32m   5542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pankajmathur/anaconda/envs/keras-playground/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m   5596\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_object_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5597\u001b[0m     return _convert_object_array(content, columns, dtype=dtype,\n\u001b[0;32m-> 5598\u001b[0;31m                                  coerce_float=coerce_float)\n\u001b[0m\u001b[1;32m   5599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/pankajmathur/anaconda/envs/keras-playground/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_convert_object_array\u001b[0;34m(content, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m   5655\u001b[0m             \u001b[0;31m# caller's responsibility to check for this...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5656\u001b[0m             raise AssertionError('%d columns passed, passed data had %s '\n\u001b[0;32m-> 5657\u001b[0;31m                                  'columns' % (len(columns), len(content)))\n\u001b[0m\u001b[1;32m   5658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5659\u001b[0m     \u001b[0;31m# provide soft conversion of object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 2 columns passed, passed data had 21 columns"
     ]
    }
   ],
   "source": [
    "comparsion_sheet = pd.DataFrame([pd_testing_set.iloc[:,1].values,predicted_stock_price], columns=['Real_Open_Price','Predicted_Open_Price'])\n",
    "comparsion_sheet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
